{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/batuhanyardim/.pyenv/versions/3.6.1/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/batuhanyardim/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras_pandas.Automater import Automater\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.load('./datasets/train_uk.npz')\n",
    "X_train = train['X']\n",
    "y_train = train['y']\n",
    "\n",
    "test = np.load('./datasets/test_uk.npz')\n",
    "X_test = test['X']\n",
    "y_test = test['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "reg = 1e-3\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(units=90, activation='tanh', input_dim=input_dim,\n",
    "                             kernel_regularizer=keras.regularizers.l2(reg),\n",
    "                             kernel_initializer=keras.initializers.glorot_normal(seed=None)))\n",
    "model.add(keras.layers.Dense(units=1, activation='sigmoid',\n",
    "                             kernel_regularizer=keras.regularizers.l2(reg),\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None)))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.SGD(lr=2e-5, momentum=0.9, nesterov=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/batuhanyardim/.pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 205438 samples, validate on 22827 samples\n",
      "Epoch 1/50\n",
      "205438/205438 [==============================] - 2s 11us/step - loss: 0.4967 - acc: 0.8494 - val_loss: 0.4857 - val_acc: 0.8522\n",
      "Epoch 2/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4895 - acc: 0.8494 - val_loss: 0.4840 - val_acc: 0.8522\n",
      "Epoch 3/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4882 - acc: 0.8494 - val_loss: 0.4829 - val_acc: 0.8522\n",
      "Epoch 4/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4874 - acc: 0.8494 - val_loss: 0.4823 - val_acc: 0.8522\n",
      "Epoch 5/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4868 - acc: 0.8494 - val_loss: 0.4818 - val_acc: 0.8522\n",
      "Epoch 6/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4864 - acc: 0.8494 - val_loss: 0.4815 - val_acc: 0.8522\n",
      "Epoch 7/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4861 - acc: 0.8494 - val_loss: 0.4812 - val_acc: 0.8522\n",
      "Epoch 8/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4858 - acc: 0.8494 - val_loss: 0.4810 - val_acc: 0.8522\n",
      "Epoch 9/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4857 - acc: 0.8494 - val_loss: 0.4809 - val_acc: 0.8522\n",
      "Epoch 10/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4855 - acc: 0.8494 - val_loss: 0.4807 - val_acc: 0.8522\n",
      "Epoch 11/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4854 - acc: 0.8494 - val_loss: 0.4806 - val_acc: 0.8522\n",
      "Epoch 12/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4853 - acc: 0.8494 - val_loss: 0.4805 - val_acc: 0.8522\n",
      "Epoch 13/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4852 - acc: 0.8494 - val_loss: 0.4804 - val_acc: 0.8522\n",
      "Epoch 14/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4851 - acc: 0.8494 - val_loss: 0.4803 - val_acc: 0.8522\n",
      "Epoch 15/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4850 - acc: 0.8494 - val_loss: 0.4802 - val_acc: 0.8522\n",
      "Epoch 16/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4849 - acc: 0.8494 - val_loss: 0.4801 - val_acc: 0.8522\n",
      "Epoch 17/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4848 - acc: 0.8494 - val_loss: 0.4800 - val_acc: 0.8522\n",
      "Epoch 18/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4847 - acc: 0.8494 - val_loss: 0.4799 - val_acc: 0.8522\n",
      "Epoch 19/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4847 - acc: 0.8494 - val_loss: 0.4798 - val_acc: 0.8522\n",
      "Epoch 20/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4846 - acc: 0.8494 - val_loss: 0.4797 - val_acc: 0.8522\n",
      "Epoch 21/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4845 - acc: 0.8494 - val_loss: 0.4797 - val_acc: 0.8522\n",
      "Epoch 22/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4845 - acc: 0.8494 - val_loss: 0.4796 - val_acc: 0.8522\n",
      "Epoch 23/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4844 - acc: 0.8494 - val_loss: 0.4795 - val_acc: 0.8522\n",
      "Epoch 24/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4843 - acc: 0.8494 - val_loss: 0.4795 - val_acc: 0.8522\n",
      "Epoch 25/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4843 - acc: 0.8494 - val_loss: 0.4794 - val_acc: 0.8522\n",
      "Epoch 26/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4842 - acc: 0.8494 - val_loss: 0.4793 - val_acc: 0.8522\n",
      "Epoch 27/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4841 - acc: 0.8494 - val_loss: 0.4793 - val_acc: 0.8522\n",
      "Epoch 28/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4841 - acc: 0.8494 - val_loss: 0.4792 - val_acc: 0.8522\n",
      "Epoch 29/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4840 - acc: 0.8494 - val_loss: 0.4791 - val_acc: 0.8522\n",
      "Epoch 30/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4840 - acc: 0.8494 - val_loss: 0.4791 - val_acc: 0.8522\n",
      "Epoch 31/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4839 - acc: 0.8494 - val_loss: 0.4790 - val_acc: 0.8522\n",
      "Epoch 32/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4839 - acc: 0.8494 - val_loss: 0.4789 - val_acc: 0.8522\n",
      "Epoch 33/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4838 - acc: 0.8494 - val_loss: 0.4789 - val_acc: 0.8522\n",
      "Epoch 34/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4837 - acc: 0.8494 - val_loss: 0.4788 - val_acc: 0.8522\n",
      "Epoch 35/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4837 - acc: 0.8494 - val_loss: 0.4787 - val_acc: 0.8522\n",
      "Epoch 36/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4836 - acc: 0.8494 - val_loss: 0.4786 - val_acc: 0.8522\n",
      "Epoch 37/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4836 - acc: 0.8494 - val_loss: 0.4786 - val_acc: 0.8522\n",
      "Epoch 38/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4835 - acc: 0.8494 - val_loss: 0.4785 - val_acc: 0.8522\n",
      "Epoch 39/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4835 - acc: 0.8494 - val_loss: 0.4785 - val_acc: 0.8522\n",
      "Epoch 40/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4834 - acc: 0.8494 - val_loss: 0.4784 - val_acc: 0.8522\n",
      "Epoch 41/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4834 - acc: 0.8494 - val_loss: 0.4784 - val_acc: 0.8522\n",
      "Epoch 42/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4833 - acc: 0.8494 - val_loss: 0.4783 - val_acc: 0.8522\n",
      "Epoch 43/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4833 - acc: 0.8494 - val_loss: 0.4782 - val_acc: 0.8522\n",
      "Epoch 44/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4832 - acc: 0.8494 - val_loss: 0.4782 - val_acc: 0.8522\n",
      "Epoch 45/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4832 - acc: 0.8494 - val_loss: 0.4781 - val_acc: 0.8522\n",
      "Epoch 46/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4831 - acc: 0.8494 - val_loss: 0.4780 - val_acc: 0.8522\n",
      "Epoch 47/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4831 - acc: 0.8494 - val_loss: 0.4780 - val_acc: 0.8522\n",
      "Epoch 48/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4830 - acc: 0.8494 - val_loss: 0.4779 - val_acc: 0.8522\n",
      "Epoch 49/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4830 - acc: 0.8494 - val_loss: 0.4779 - val_acc: 0.8522\n",
      "Epoch 50/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4829 - acc: 0.8494 - val_loss: 0.4778 - val_acc: 0.8522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1378d2978>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_split=0.1,\n",
    "          batch_size=600, nb_epoch=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_train)\n",
    "\n",
    "plt.hist(y_pred, bins=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some other hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/batuhanyardim/.pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 205438 samples, validate on 22827 samples\n",
      "Epoch 1/50\n",
      "205438/205438 [==============================] - 2s 12us/step - loss: 0.4895 - acc: 0.8090 - val_loss: 0.4283 - val_acc: 0.8522\n",
      "Epoch 2/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4322 - acc: 0.8494 - val_loss: 0.4267 - val_acc: 0.8522\n",
      "Epoch 3/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4313 - acc: 0.8494 - val_loss: 0.4261 - val_acc: 0.8522\n",
      "Epoch 4/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4309 - acc: 0.8494 - val_loss: 0.4258 - val_acc: 0.8522\n",
      "Epoch 5/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4306 - acc: 0.8494 - val_loss: 0.4255 - val_acc: 0.8522\n",
      "Epoch 6/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4304 - acc: 0.8494 - val_loss: 0.4253 - val_acc: 0.8522\n",
      "Epoch 7/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4303 - acc: 0.8494 - val_loss: 0.4252 - val_acc: 0.8522\n",
      "Epoch 8/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4301 - acc: 0.8494 - val_loss: 0.4251 - val_acc: 0.8522\n",
      "Epoch 9/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4300 - acc: 0.8494 - val_loss: 0.4250 - val_acc: 0.8522\n",
      "Epoch 10/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4299 - acc: 0.8494 - val_loss: 0.4249 - val_acc: 0.8522\n",
      "Epoch 11/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4299 - acc: 0.8494 - val_loss: 0.4248 - val_acc: 0.8522\n",
      "Epoch 12/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4298 - acc: 0.8494 - val_loss: 0.4247 - val_acc: 0.8522\n",
      "Epoch 13/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4297 - acc: 0.8494 - val_loss: 0.4247 - val_acc: 0.8522\n",
      "Epoch 14/50\n",
      "205438/205438 [==============================] - 2s 12us/step - loss: 0.4297 - acc: 0.8494 - val_loss: 0.4246 - val_acc: 0.8522\n",
      "Epoch 15/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4296 - acc: 0.8494 - val_loss: 0.4246 - val_acc: 0.8522\n",
      "Epoch 16/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4296 - acc: 0.8494 - val_loss: 0.4245 - val_acc: 0.8522\n",
      "Epoch 17/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4295 - acc: 0.8494 - val_loss: 0.4245 - val_acc: 0.8522\n",
      "Epoch 18/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4295 - acc: 0.8494 - val_loss: 0.4244 - val_acc: 0.8522\n",
      "Epoch 19/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4295 - acc: 0.8494 - val_loss: 0.4244 - val_acc: 0.8522\n",
      "Epoch 20/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4294 - acc: 0.8494 - val_loss: 0.4244 - val_acc: 0.8522\n",
      "Epoch 21/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4294 - acc: 0.8494 - val_loss: 0.4243 - val_acc: 0.8522\n",
      "Epoch 22/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4294 - acc: 0.8494 - val_loss: 0.4243 - val_acc: 0.8522\n",
      "Epoch 23/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4293 - acc: 0.8494 - val_loss: 0.4243 - val_acc: 0.8522\n",
      "Epoch 24/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4293 - acc: 0.8494 - val_loss: 0.4243 - val_acc: 0.8522\n",
      "Epoch 25/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4293 - acc: 0.8494 - val_loss: 0.4242 - val_acc: 0.8522\n",
      "Epoch 26/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4292 - acc: 0.8494 - val_loss: 0.4242 - val_acc: 0.8522\n",
      "Epoch 27/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4292 - acc: 0.8494 - val_loss: 0.4242 - val_acc: 0.8522\n",
      "Epoch 28/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4292 - acc: 0.8494 - val_loss: 0.4242 - val_acc: 0.8522\n",
      "Epoch 29/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4292 - acc: 0.8494 - val_loss: 0.4241 - val_acc: 0.8522\n",
      "Epoch 30/50\n",
      "205438/205438 [==============================] - ETA: 0s - loss: 0.4292 - acc: 0.849 - 1s 7us/step - loss: 0.4292 - acc: 0.8494 - val_loss: 0.4241 - val_acc: 0.8522\n",
      "Epoch 31/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4291 - acc: 0.8494 - val_loss: 0.4241 - val_acc: 0.8522\n",
      "Epoch 32/50\n",
      "205438/205438 [==============================] - 1s 6us/step - loss: 0.4291 - acc: 0.8494 - val_loss: 0.4241 - val_acc: 0.8522\n",
      "Epoch 33/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4291 - acc: 0.8494 - val_loss: 0.4241 - val_acc: 0.8522\n",
      "Epoch 34/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4291 - acc: 0.8494 - val_loss: 0.4240 - val_acc: 0.8522\n",
      "Epoch 35/50\n",
      "205438/205438 [==============================] - 1s 7us/step - loss: 0.4291 - acc: 0.8494 - val_loss: 0.4240 - val_acc: 0.8522\n",
      "Epoch 36/50\n",
      "205438/205438 [==============================] - 2s 7us/step - loss: 0.4290 - acc: 0.8494 - val_loss: 0.4240 - val_acc: 0.8522\n",
      "Epoch 37/50\n",
      "205438/205438 [==============================] - 2s 12us/step - loss: 0.4290 - acc: 0.8494 - val_loss: 0.4240 - val_acc: 0.8522\n",
      "Epoch 38/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4290 - acc: 0.8494 - val_loss: 0.4240 - val_acc: 0.8522\n",
      "Epoch 39/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4290 - acc: 0.8494 - val_loss: 0.4240 - val_acc: 0.8522\n",
      "Epoch 40/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4290 - acc: 0.8494 - val_loss: 0.4239 - val_acc: 0.8522\n",
      "Epoch 41/50\n",
      "205438/205438 [==============================] - 2s 10us/step - loss: 0.4290 - acc: 0.8494 - val_loss: 0.4239 - val_acc: 0.8522\n",
      "Epoch 42/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4290 - acc: 0.8494 - val_loss: 0.4239 - val_acc: 0.8522\n",
      "Epoch 43/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4239 - val_acc: 0.8522\n",
      "Epoch 44/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4239 - val_acc: 0.8522\n",
      "Epoch 45/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4239 - val_acc: 0.8522\n",
      "Epoch 46/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4239 - val_acc: 0.8522\n",
      "Epoch 47/50\n",
      "205438/205438 [==============================] - 2s 8us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4238 - val_acc: 0.8522\n",
      "Epoch 48/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4238 - val_acc: 0.8522\n",
      "Epoch 49/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4238 - val_acc: 0.8522\n",
      "Epoch 50/50\n",
      "205438/205438 [==============================] - 2s 9us/step - loss: 0.4289 - acc: 0.8494 - val_loss: 0.4238 - val_acc: 0.8522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ab13be0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "\n",
    "reg = 2e-5\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(units=90, activation='tanh', input_dim=input_dim,\n",
    "                             kernel_regularizer=keras.regularizers.l2(reg),\n",
    "                             kernel_initializer=keras.initializers.glorot_normal(seed=None)))\n",
    "# model.add(keras.layers.Dense(units=90, activation='tanh',\n",
    "#                              kernel_regularizer=keras.regularizers.l2(reg),\n",
    "#                              kernel_initializer=keras.initializers.glorot_normal(seed=None)))\n",
    "model.add(keras.layers.Dense(units=1, activation='sigmoid',\n",
    "                             kernel_regularizer=keras.regularizers.l2(reg),\n",
    "                            kernel_initializer=keras.initializers.glorot_normal(seed=None)))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'],\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-4, momentum=0.9, nesterov=True, decay=0.04))\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.1,\n",
    "          batch_size=600, nb_epoch=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.0000e+00, 1.0800e+02, 7.5200e+02, 3.3520e+03, 8.0240e+03,\n",
       "        1.0674e+04, 1.4006e+04, 2.1227e+04, 2.2737e+04, 1.8287e+04,\n",
       "        1.5162e+04, 1.9140e+04, 2.2191e+04, 2.4720e+04, 2.0550e+04,\n",
       "        1.1926e+04, 6.0540e+03, 3.0850e+03, 2.1630e+03, 1.2900e+03,\n",
       "        1.0010e+03, 5.6400e+02, 4.7100e+02, 2.9000e+02, 1.9600e+02,\n",
       "        1.1600e+02, 6.1000e+01, 3.9000e+01, 2.6000e+01, 3.0000e+01,\n",
       "        5.0000e+00, 6.0000e+00, 4.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0000e+00]),\n",
       " array([0.11066955, 0.11479264, 0.11891574, 0.12303884, 0.12716193,\n",
       "        0.13128504, 0.13540813, 0.13953124, 0.14365433, 0.14777744,\n",
       "        0.15190053, 0.15602364, 0.16014673, 0.16426983, 0.16839293,\n",
       "        0.17251602, 0.17663912, 0.18076222, 0.18488532, 0.18900841,\n",
       "        0.19313152, 0.19725461, 0.20137772, 0.20550081, 0.20962392,\n",
       "        0.21374701, 0.21787012, 0.22199321, 0.2261163 , 0.2302394 ,\n",
       "        0.2343625 , 0.2384856 , 0.2426087 , 0.2467318 , 0.2508549 ,\n",
       "        0.254978  , 0.2591011 , 0.26322418, 0.2673473 , 0.2714704 ,\n",
       "        0.2755935 ], dtype=float32),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred[y_pred<0.4], bins=40);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('./models/weight1.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('./models/arch1.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
